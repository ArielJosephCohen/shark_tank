{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data: https://www.kaggle.com/rahulsathyajit/shark-tank-pitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('shark_tank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(df.deal[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.deal=(df.deal).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Multiple Entreprenuers']=(df['Multiple Entreprenuers']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df.location.iloc[i]=df.location[i].split(',')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.askedFor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['website_length']=0\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        df['website_length'][i]=len(df.website[i])\n",
    "    except:\n",
    "        df['website_length'][i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(df.website_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(df.website_length,bins=3).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.website_length=pd.cut(df.website_length,bins=3,labels=['short','medium','long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "j=0\n",
    "colors=['red','blue','yellow']\n",
    "plt.figure(figsize=(15,8))\n",
    "for col in ['askedFor','valuation','exchangeForStake']:\n",
    "    plt.subplot(2,2,i)\n",
    "    sns.violinplot(df[col],color=colors[j])\n",
    "    i=i+1\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_outliers(dataframe,threshold):\n",
    "    \"\"\"\n",
    "    Input a data frame and have all outliers filtered to a certain and custom threshold of standard deviations\n",
    "    \"\"\"\n",
    "    dataframe = dataframe[(np.abs(stats.zscore(dataframe)) <= threshold).all(axis=1)]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.website_length=df.website_length.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_num = filter_outliers(df.select_dtypes(include=[int,float]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "j=0\n",
    "colors=['red','blue','yellow']\n",
    "plt.figure(figsize=(15,8))\n",
    "for col in ['askedFor','valuation','exchangeForStake']:\n",
    "    plt.subplot(2,2,i)\n",
    "    sns.violinplot(df_filter_num[col],color=colors[j])\n",
    "    i=i+1\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_num['asked_size']=pd.cut(df_filter_num.askedFor,bins=3,labels=['small','medium','large'])\n",
    "df_filter_num['value_size']=pd.cut(df_filter_num.askedFor,bins=3,labels=['small','medium','large'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_cat = df[df.index.isin(df_filter_num.index)].select_dtypes(include='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter=pd.concat([df_filter_cat,df_filter_num],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_filter.shape)\n",
    "df_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_filter.askedFor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.website.fillna('none',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_filter)):\n",
    "    if df_filter.website[i]=='none':\n",
    "        df_filter.website[i]=0\n",
    "    else:\n",
    "        df_filter.website[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_cat_df=pd.get_dummies(df_filter.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_cat_df=pitch_cat_df.drop(\"Women's Shoes\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in pitch_cat_df.columns:\n",
    "    df_filter[col]=pitch_cat_df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter['sharks']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_filter)):\n",
    "    df_filter['sharks'][i]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_filter)):\n",
    "    df_filter['sharks'][i].append([df_filter.shark1[i],df_filter.shark2[i],df_filter.shark3[i],df_filter.shark4[i],df_filter.shark5[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_filter)):\n",
    "    df_filter.sharks[i]=df_filter.sharks[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.sharks.astype(str).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharks_dict={\n",
    "    'group_1':['Barbara Corcoran', 'Robert Herjavec', \"Kevin O'Leary\", 'Daymond John', 'Kevin Harrington'],\n",
    "    'group_2':['Barbara Corcoran', 'Robert Herjavec', \"Kevin O'Leary\", 'Daymond John', 'Mark Cuban'],\n",
    "    'group_3':['Barbara Corcoran', 'Robert Herjavec', \"Kevin O'Leary\", 'Jeff Foxworthy', 'Daymond John'],\n",
    "    'group_4':['Lori Greiner', 'Robert Herjavec', \"Kevin O'Leary\", 'Daymond John', 'Mark Cuban'],\n",
    "    'group_5':['Lori Greiner', 'Barbara Corcoran', 'Robert Herjavec', \"Kevin O\\'Leary\", 'Mark Cuban'],\n",
    "    'group_6':['Lori Greiner', \"Kevin O'Leary\", 'Daymond John', 'Mark Cuban', 'John Paul DeJoria'],\n",
    "    'group_7':['Lori Greiner', 'Steve Tisch', \"Kevin O'Leary\", 'Daymond John', 'Mark Cuban'],\n",
    "    'group_8':['Lori Greiner', \"Kevin O'Leary\", 'Daymond John', 'Mark Cuban', 'Nick Woodman']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter['shark_group']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_filter)):\n",
    "    if df_filter.sharks[i]==sharks_dict['group_1']:\n",
    "        df_filter.shark_group[i]=1\n",
    "    elif df_filter.sharks[i]==sharks_dict['group_2']:\n",
    "        df_filter.shark_group[i]=2\n",
    "    elif df_filter.sharks[i]==sharks_dict['group_3']:\n",
    "        df_filter.shark_group[i]=3\n",
    "    elif df_filter.sharks[i]==sharks_dict['group_4']:\n",
    "        df_filter.shark_group[i]=4\n",
    "    elif df_filter.sharks[i]==sharks_dict['group_5']:\n",
    "        df_filter.shark_group[i]=5\n",
    "    elif df_filter.sharks[i]==sharks_dict['group_6']:\n",
    "        df_filter.shark_group[i]=6\n",
    "    elif df_filter.sharks[i]==sharks_dict['group_7']:\n",
    "        df_filter.shark_group[i]=7\n",
    "    else:\n",
    "        df_filter.shark_group[i]=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.iloc[:,0:15].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.iloc[:,15:30].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.iloc[:,30:45].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.iloc[:,45:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter=df_filter[['deal','description','category', 'entrepreneurs', 'location', 'website', 'website_length','shark1',\n",
    "       'shark2', 'shark3', 'shark4', 'shark5','sharks',\n",
    "       'shark_group' ,'title', 'episode-season', 'episode', 'askedFor', 'exchangeForStake', 'valuation',\n",
    "       'season', 'Multiple_Entreprenuers', 'asked_size', 'value_size',\n",
    "       'Alcoholic Beverages', 'Automotive', 'Baby and Child Care',\n",
    "       \"Baby and Children's Apparel and Accessories\",\n",
    "       \"Baby and Children's Bedding\", \"Baby and Children's Entertainment\",\n",
    "       \"Baby and Children's Food\", 'Consumer Services', 'Costumes', 'Cycling',\n",
    "       'Education', 'Electronics', 'Entertainment', 'Fashion Accessories',\n",
    "       'Fitness Apparel and Accessories', 'Fitness Equipment',\n",
    "       'Fitness Programs', 'Furniture', 'Gardening', 'Golf Products',\n",
    "       'Health and Well-Being', 'Holiday Cheer', 'Home Accessories',\n",
    "       'Home Improvement', 'Home Security Solutions', 'Homeopathic Remedies',\n",
    "       'Kitchen Tools', 'Maternity', \"Men and Women's Accessories\",\n",
    "       \"Men and Women's Apparel\", \"Men and Women's Shoes\", \"Men's Accessories\",\n",
    "       'Mobile Apps', 'Music', 'Non-Alcoholic Beverages', 'Novelties',\n",
    "       'Online Services', 'Outdoor Recreation', 'Party Supplies',\n",
    "       'Personal Care and Cosmetics', 'Pest Control', 'Pet Products',\n",
    "       'Productivity Tools', 'Professional Services', 'Specialty Food',\n",
    "       'Storage and Cleaning Products', 'Toys and Games',\n",
    "       'Undergarments and Basics', 'Water Bottles', 'Weddings',\n",
    "       'Wine Accessories', \"Women's Accessories\", \"Women's Apparel\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_basic=df_filter.iloc[:,0:24]\n",
    "df_filter_dummies=df_filter.iloc[:,24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filter_basic.to_csv('cleaned_shark.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I need to address categorical data numerically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(abs(df_filter_basic.corr()>=0.7),cmap='plasma')\n",
    "plt.tight_layout()\n",
    "plt.title('correlation between features matchin 70% or higher')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_basic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encode(df,target,col):\n",
    "    \n",
    "    dummy_dict = {}\n",
    "    dummy_df = df[[col,target]].groupby(col,as_index=False).mean()\n",
    "    for i in range(len(dummy_df)):\n",
    "        dummy_dict[dummy_df.iloc[i,0]]=dummy_df.iloc[i,1]\n",
    "    df[col]=df[col].map(lambda x: dummy_dict[x])\n",
    "    \n",
    "    return df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_basic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unique and un-needed values\n",
    "df_filter_basic.drop(['description','sharks','title','episode-season','category','entrepreneurs'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_basic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_basic.shark_group=df_filter_basic.shark_group.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_basic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_filter_basic.select_dtypes(exclude=[int,float]).columns:\n",
    "    df_filter_basic[col]=target_encode(df_filter_basic,'deal',col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_basic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_filter_basic.columns:\n",
    "    df_filter_basic[col]=df_filter_basic[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_basic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_filter_dummies.columns:\n",
    "    df_filter_dummies[col]=df_filter_dummies[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(abs(df_filter_basic.corr()>=0.7),cmap='mako')\n",
    "plt.tight_layout()\n",
    "plt.title('correlation between features matchin 70% or higher')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_basic.drop(['season','value_size'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(abs(df_filter_basic.corr()>=0.8),cmap='magma_r')\n",
    "plt.tight_layout()\n",
    "plt.title('correlation between features matchin 80% or higher')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_basic.drop(['shark_group'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(abs(df_filter_basic.corr()>=0.85),cmap='summer')\n",
    "plt.tight_layout()\n",
    "plt.title('correlation between features matchin 85% or higher')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I'd like to keep info on which shark was in even though it has high correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_filter_basic,df_filter_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target']=df.deal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.Target\n",
    "X=df.drop(['deal','Target'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "X_ss=df.copy()\n",
    "ss = StandardScaler()\n",
    "for col in X_ss.columns:\n",
    "    X_ss[col]=scaler.fit_transform(X_ss[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "X_ma=X.copy()\n",
    "X_ma = MaxAbsScaler()\n",
    "for col in df_ma.columns:\n",
    "    X_ma[col]=scaler.fit_transform(X_ma[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensionality reduction\n",
    "## this code is designed to find the number of features needed in the X data for an optimal accuracy score\n",
    "\n",
    "def optimize_score_rfe(scaler, dataframe,method,style,target_variable,ts,cross_val=5,goal='accuracy'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input a goal, method, style (the method of analysis written as a string), and number of cross validations and \n",
    "    receive an optimal score, number of features used, and list of features used as an output\n",
    "    \"\"\"\n",
    "    \n",
    "    # Imports and initializing variables\n",
    "    mms = scaler\n",
    "    old_score = 0\n",
    "    old_features_used = 1\n",
    "\n",
    "    # Optimize features needed\n",
    "    for i in range(1,df.shape[1]):\n",
    "        y = dataframe.Target\n",
    "        X = dataframe.drop('Target',axis=1)\n",
    "        selector = RFE(method,n_features_to_select=i)\n",
    "        # selector = RFECV(estimator=method, step=1, cv=StratifiedKFold(cross_val), scoring=goal,min_features_to_select=i)\n",
    "        selector = selector.fit(X, y.values.ravel())\n",
    "        selected_columns = X.columns[selector.support_]\n",
    "        new_y = dataframe.Target\n",
    "        new_X = dataframe[selected_columns]\n",
    "        for col in new_X.columns:\n",
    "            new_X[col] = mms.fit_transform(new_X[[col]])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(new_X,new_y,test_size=ts,random_state=14) \n",
    "        method.fit(X_train,y_train)\n",
    "        Y_pred = method.predict(X_test)\n",
    "        if style == 'Linear_Regression':\n",
    "            accuracy = r2_score(y_test, Y_pred)\n",
    "        else:\n",
    "            accuracy = accuracy_score(y_test, Y_pred)\n",
    "        new_score = accuracy\n",
    "        if new_score > old_score:\n",
    "            score = new_score\n",
    "            features_used = i\n",
    "            old_score = new_score\n",
    "            old_features_used = i\n",
    "        else:\n",
    "            score = old_score\n",
    "            features_used = old_features_used\n",
    "    \n",
    "        # crate new data frame based on work\n",
    "        # selector_new = RFECV(estimator=method, step=1, cv=StratifiedKFold(cross_val), scoring='accuracy',min_features_to_select=features_used)\n",
    "        selector_new = RFE(method,n_features_to_select=features_used)\n",
    "        selector_new = selector_new.fit(X, y.values.ravel())\n",
    "        selected_columns_new = X.columns[selector_new.support_]\n",
    "        \n",
    "    # print discoveries\n",
    "    print(f'Predicting: {target_variable}')\n",
    "    print('')\n",
    "    print(f'The optimal score is {100*round(score,2)}%, and it makes use of {features_used} features from the data.')\n",
    "    print('')\n",
    "    print(f'Those features are: {list(selected_columns_new)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensionality reduction\n",
    "## principal component analysis\n",
    "\n",
    "def run_pca(X_tr,components):\n",
    "    pca = PCA(n_components=components)\n",
    "    pca.fit(X_tr)\n",
    "    cumsum = np.cumsum(pca.explained_variance_ratio_)*100\n",
    "    d = [n for n in range(len(cumsum))]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(d, cumsum, color='red', label = 'Explained Variance')\n",
    "    plt.title('Explained Variance vs Number of Components')\n",
    "    plt.ylabel('Explained Variance')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.axhline(y = 90, color='k', linestyle='--', label = '90% of Explained Variance')\n",
    "    plt.legend(loc='best')\n",
    "    #X_train_pca = pd.DataFrame(pca_fraud.fit_transform(X_train))\n",
    "    #X_test_pca = pd.DataFrame(pca_fraud.transform(X_test))\n",
    "    #train_pca = X_train_pca.copy()\n",
    "    #train_pca.target=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=14,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_model(mod):\n",
    "    model=mod\n",
    "    model.fit(X_train,y_train)\n",
    "    pred=mod.predict(X_test)\n",
    "    sns.heatmap(confusion_matrix(y_test,pred),cmap='winter')\n",
    "    print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "svm=SVC()\n",
    "knn=KNeighborsClassifier()\n",
    "logreg=LogisticRegression()\n",
    "sgd=SGDClassifier()\n",
    "rf=RandomForestClassifier(random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi=pd.DataFrame(rf.feature_importances_).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.columns=X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_1=fi.T.sort_values(by=0,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style({'axes.facecolor':'black'}):\n",
    "    fi_1[0:25].plot(kind='barh',figsize=(15,8),color='white')\n",
    "    plt.tight_layout()\n",
    "    plt.title('feature importances by magnitude')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train,y_train)\n",
    "pred=rf.predict(X_test)\n",
    "sns.heatmap(confusion_matrix(y_test,pred),cmap='winter')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi=pd.DataFrame(logreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.columns=X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_1=fi.T.sort_values(by=0,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style({'axes.facecolor':'m'}):\n",
    "    fi_1.plot(kind='barh',figsize=(15,9),color='limegreen')\n",
    "    plt.tight_layout()\n",
    "    plt.title('feature importances with sign')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model again with no sharks correlation and with gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['shark1','shark2','shark3','shark4','shark5'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.Target\n",
    "X=df.drop(['deal','Target'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=14,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model(logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi=pd.DataFrame(logreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.columns=X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_1=fi.T.sort_values(by=0,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style({'axes.facecolor':'lightgreen'}):\n",
    "    fi_1.plot(kind='barh',figsize=(15,9),color='forestgreen')\n",
    "    plt.tight_layout()\n",
    "    plt.title('feature importances with sign')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
